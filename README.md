### Vanilla RNN
#### Implemeted vanilla RNN using pytorch without using RNN library
#### Used nn.Linear to model the weights of the RNN

### LSTM
#### LSTM are gated RNNs which helo to mitigate the effects of exploding or diminishing gradients
#### Various channels decide how much of the past is passed forward and how much of it is forgot
#### The LSTM, like vanilla RNN, is implemented from scratch using nn.Linear to model the weights
